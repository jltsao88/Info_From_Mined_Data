{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment deals with evaluating Hearful predictive model performance against hand validated results.\n",
    "\n",
    "Hearful relies upon a human validator to evaluate the performance of its models. The human validator is presented with the same set of 300 reviews that the model is run against to produce a similarly structured file containing predictions for the presence of specific themes as well as the sentiment associated with those themes.\n",
    "\n",
    "For this task, you will be analyzing a human validated output for the same set of 300 reviews, contained in the file APPAREL_ODOM_1_2019.csv. Your task is to write a Python script to evaluate the performance of the model on the following metrics: precision, recall, accuracy, and f-measure.\n",
    "\n",
    "The metrics should be computed via standard formulas, using a 2x2 matrix, with true positive, true negative, false positive, and false negative values computed for each theme and each themeâ€™s sentiment independently. The results should be presented similarly to the below table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please remember, that the human validator result is taken as the golden standard. Therefore, if a certain result is marked as present by the validator but is not present in the model prediction, that is counted as a false negative. Conversely, if a model predicted an outcome not marked by the validator, that is considered a false positive.\n",
    "\n",
    "Please justify any assumptions you make in your computation and submit all code and output files to the GitHub repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Positive Classes in Binary Classification Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive Class For Themes Exists columns: 1\n",
    "    \n",
    "Positive Class For Theme Sentiment Columns: 'pos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Validation and Prediction Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Display full columns in pandas dataframes\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Human Validator Set\n",
    "human_df = pd.read_csv('APPAREL_ODOM_1_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 298 entries, 0 to 297\n",
      "Data columns (total 16 columns):\n",
      "_id                        298 non-null object\n",
      "domain_global_string       298 non-null object\n",
      "review_rating              298 non-null int64\n",
      "notes                      97 non-null object\n",
      "review_text                298 non-null object\n",
      "review_title               278 non-null object\n",
      "use_sentiment_label        110 non-null object\n",
      "use_theme_exists           298 non-null int64\n",
      "fit_sentiment_label        209 non-null object\n",
      "fit_theme_exists           298 non-null int64\n",
      "value_sentiment_label      101 non-null object\n",
      "value_theme_exists         298 non-null int64\n",
      "style_sentiment_label      120 non-null object\n",
      "style_theme_exists         298 non-null int64\n",
      "quality_sentiment_label    189 non-null object\n",
      "quality_theme_exists       297 non-null float64\n",
      "dtypes: float64(1), int64(5), object(10)\n",
      "memory usage: 37.3+ KB\n"
     ]
    }
   ],
   "source": [
    "human_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prediction Set\n",
    "model_df = pd.read_csv('APPAREL_ids_1_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 15 columns):\n",
      "_id                        300 non-null object\n",
      "domain_global_string       300 non-null object\n",
      "review_rating              300 non-null int64\n",
      "review_text                300 non-null object\n",
      "review_title               278 non-null object\n",
      "use_sentiment_label        146 non-null object\n",
      "use_theme_exists           156 non-null float64\n",
      "fit_sentiment_label        220 non-null object\n",
      "fit_theme_exists           226 non-null float64\n",
      "value_sentiment_label      93 non-null object\n",
      "value_theme_exists         99 non-null float64\n",
      "style_sentiment_label      180 non-null object\n",
      "style_theme_exists         183 non-null float64\n",
      "quality_sentiment_label    201 non-null object\n",
      "quality_theme_exists       215 non-null float64\n",
      "dtypes: float64(5), int64(1), object(9)\n",
      "memory usage: 35.2+ KB\n"
     ]
    }
   ],
   "source": [
    "model_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two rows of data in the model prediction not in the human validator.  We will remove those two rows because we will not be able to calulate whether the model predicted corrected whith out knowing the true labels of the\n",
    "validator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find rows present in the prediction model not in the human model\n",
    "ids = []\n",
    "for id1 in list(model_df._id):\n",
    "    if id1 not in list(human_df._id):\n",
    "        ids.append(id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['walmart79904828', 'zappos5307009']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find rows present human model not present in the prediction model\n",
    "ids2 = []\n",
    "for id1 in list(human_df._id):\n",
    "    if id1 not in list(model_df._id):\n",
    "        ids2.append(id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove Rows from model_df not in human_df\n",
    "model_df = model_df[model_df._id.isin(list(human_df._id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 298 entries, 0 to 299\n",
      "Data columns (total 15 columns):\n",
      "_id                        298 non-null object\n",
      "domain_global_string       298 non-null object\n",
      "review_rating              298 non-null int64\n",
      "review_text                298 non-null object\n",
      "review_title               278 non-null object\n",
      "use_sentiment_label        146 non-null object\n",
      "use_theme_exists           155 non-null float64\n",
      "fit_sentiment_label        218 non-null object\n",
      "fit_theme_exists           224 non-null float64\n",
      "value_sentiment_label      92 non-null object\n",
      "value_theme_exists         98 non-null float64\n",
      "style_sentiment_label      179 non-null object\n",
      "style_theme_exists         182 non-null float64\n",
      "quality_sentiment_label    200 non-null object\n",
      "quality_theme_exists       213 non-null float64\n",
      "dtypes: float64(5), int64(1), object(9)\n",
      "memory usage: 37.2+ KB\n"
     ]
    }
   ],
   "source": [
    "model_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index of model\n",
    "model_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "5      True\n",
       "6      True\n",
       "7      True\n",
       "8      True\n",
       "9      True\n",
       "10     True\n",
       "11     True\n",
       "12     True\n",
       "13     True\n",
       "14     True\n",
       "15     True\n",
       "16     True\n",
       "17     True\n",
       "18     True\n",
       "19     True\n",
       "20     True\n",
       "21     True\n",
       "22     True\n",
       "23     True\n",
       "24     True\n",
       "25     True\n",
       "26     True\n",
       "27     True\n",
       "28     True\n",
       "29     True\n",
       "       ... \n",
       "268    True\n",
       "269    True\n",
       "270    True\n",
       "271    True\n",
       "272    True\n",
       "273    True\n",
       "274    True\n",
       "275    True\n",
       "276    True\n",
       "277    True\n",
       "278    True\n",
       "279    True\n",
       "280    True\n",
       "281    True\n",
       "282    True\n",
       "283    True\n",
       "284    True\n",
       "285    True\n",
       "286    True\n",
       "287    True\n",
       "288    True\n",
       "289    True\n",
       "290    True\n",
       "291    True\n",
       "292    True\n",
       "293    True\n",
       "294    True\n",
       "295    True\n",
       "296    True\n",
       "297    True\n",
       "Name: _id, Length: 298, dtype: bool"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to see if ids match and align in both datasets\n",
    "#Will throw an error if this is not so\n",
    "model_df._id == human_df._id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Join the dataframes together to better compare the data\n",
    "df_joined = model_df.merge(human_df, how='inner', on='_id',suffixes=('_pred', '_val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#columns to drop so dataframe is easier to read\n",
    "cols = ['index', 'domain_global_string_pred', 'review_rating_pred', 'review_text_pred',\n",
    "        'review_title_pred', 'notes', 'review_text_val', 'domain_global_string_val',\n",
    "        'review_rating_val', 'review_title_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_joined.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>use_sentiment_label_pred</th>\n",
       "      <th>use_theme_exists_pred</th>\n",
       "      <th>fit_sentiment_label_pred</th>\n",
       "      <th>fit_theme_exists_pred</th>\n",
       "      <th>value_sentiment_label_pred</th>\n",
       "      <th>value_theme_exists_pred</th>\n",
       "      <th>style_sentiment_label_pred</th>\n",
       "      <th>style_theme_exists_pred</th>\n",
       "      <th>quality_sentiment_label_pred</th>\n",
       "      <th>quality_theme_exists_pred</th>\n",
       "      <th>use_sentiment_label_val</th>\n",
       "      <th>use_theme_exists_val</th>\n",
       "      <th>fit_sentiment_label_val</th>\n",
       "      <th>fit_theme_exists_val</th>\n",
       "      <th>value_sentiment_label_val</th>\n",
       "      <th>value_theme_exists_val</th>\n",
       "      <th>style_sentiment_label_val</th>\n",
       "      <th>style_theme_exists_val</th>\n",
       "      <th>quality_sentiment_label_val</th>\n",
       "      <th>quality_theme_exists_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy58403947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adidas100338674</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adidas102938471</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazonR17DE72WNC7FQM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazonR19HL1JO6GEKJK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id use_sentiment_label_pred  use_theme_exists_pred  \\\n",
       "0  academy58403947       NaN                     NaN                      \n",
       "1  adidas100338674       pos                      1.0                     \n",
       "2  adidas102938471       pos                      1.0                     \n",
       "3  amazonR17DE72WNC7FQM  NaN                     NaN                      \n",
       "4  amazonR19HL1JO6GEKJK  NaN                     NaN                      \n",
       "\n",
       "  fit_sentiment_label_pred  fit_theme_exists_pred value_sentiment_label_pred  \\\n",
       "0  NaN                     NaN                     pos                         \n",
       "1  NaN                     NaN                     NaN                         \n",
       "2  pos                      1.0                    pos                         \n",
       "3  NaN                     NaN                     NaN                         \n",
       "4  neg                      1.0                    pos                         \n",
       "\n",
       "   value_theme_exists_pred style_sentiment_label_pred  \\\n",
       "0  1.0                      pos                         \n",
       "1 NaN                       NaN                         \n",
       "2  1.0                      pos                         \n",
       "3 NaN                       NaN                         \n",
       "4  1.0                      NaN                         \n",
       "\n",
       "   style_theme_exists_pred quality_sentiment_label_pred  \\\n",
       "0  1.0                      NaN                           \n",
       "1 NaN                       pos                           \n",
       "2  1.0                      NaN                           \n",
       "3 NaN                       pos                           \n",
       "4 NaN                       NaN                           \n",
       "\n",
       "   quality_theme_exists_pred use_sentiment_label_val  use_theme_exists_val  \\\n",
       "0 NaN                         NaN                     0                      \n",
       "1  1.0                        NaN                     0                      \n",
       "2 NaN                         pos                     1                      \n",
       "3  1.0                        NaN                     0                      \n",
       "4 NaN                         NaN                     0                      \n",
       "\n",
       "  fit_sentiment_label_val  fit_theme_exists_val value_sentiment_label_val  \\\n",
       "0  neg                     1                     NaN                        \n",
       "1  NaN                     0                     NaN                        \n",
       "2  pos                     1                     pos                        \n",
       "3  NaN                     0                     NaN                        \n",
       "4  neg                     1                     pos                        \n",
       "\n",
       "   value_theme_exists_val style_sentiment_label_val  style_theme_exists_val  \\\n",
       "0  0                       pos                       1                        \n",
       "1  0                       pos                       1                        \n",
       "2  1                       pos                       1                        \n",
       "3  0                       NaN                       0                        \n",
       "4  1                       NaN                       0                        \n",
       "\n",
       "  quality_sentiment_label_val  quality_theme_exists_val  \n",
       "0  NaN                         0.0                       \n",
       "1  neg                         1.0                       \n",
       "2                              0.0                       \n",
       "3  neg                         1.0                       \n",
       "4  pos                         1.0                       "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comapre prediction and validation for use_sentiment_label\n",
    "df_use_sent = df_joined[['use_sentiment_label_pred', 'use_sentiment_label_val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use_sent.iloc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df_use_sent.iloc[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at sentiment labels.  In this case we are determining if a label is positive or negative.  One thing to notice is that sometimes the validation set has a value while the prediction set does not, and sometimes the prediction set has a value and the validation set does not.  In those two cases, we can not assign a value (True Positive, True Negative, False Positive, or False Negative) to the prediction.\n",
    "\n",
    "True Positive: sent_label_pred = pos & sent_label_val = pos\n",
    "\n",
    "False Positve:sent_label_pred = pos & sent_label_val = neg\n",
    "\n",
    "True Negative: sent_label_pred = neg & sent_label_val = neg\n",
    "\n",
    "False Negative: sent_label_pred = neg & sent_label_val = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use_sentiment_label_pred</th>\n",
       "      <th>use_sentiment_label_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  use_sentiment_label_pred use_sentiment_label_val\n",
       "0  NaN                      NaN                   \n",
       "1  pos                      NaN                   \n",
       "2  pos                      pos                   \n",
       "3  NaN                      NaN                   \n",
       "4  NaN                      NaN                   "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confuse_mat(tp, tn, fp, fn):\n",
    "    #Returns a 2x2 matrix\n",
    "    #[[true positve, false positive], [false negative, true negative]]\n",
    "    return [[tp, fp],\n",
    "            [fn, tn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confuse_mat_label(df_pred, df_val, label):\n",
    "    \"\"\"\n",
    "    Creates a confusion 2x2 matrix\n",
    "    [[true positve, false positive], [false negative, true negative]]\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for pred, val in list(zip(df_pred[label], df_val[label])):\n",
    "        if pred == 'pos' and val == 'pos':\n",
    "            tp += 1\n",
    "        elif pred == 'neg' and val == 'neg':\n",
    "            tn += 1\n",
    "        elif pred == 'pos' and val == 'neg':\n",
    "            fp += 1\n",
    "        elif pred == 'neg' and val =='pos':\n",
    "            fn += 1\n",
    "    return make_confuse_mat(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat = confuse_mat_label(model_df, human_df, 'use_sentiment_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[88, 3], [3, 2]]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_mat_label(model_df, human_df, 'use_sentiment_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Looking at the theme exists columns we have to take into a account for things a little differently to identify false negatives and true negatives.\n",
    "\n",
    "True Positive: theme_exists_pred = 1 & theme_exists_val = 1\n",
    "\n",
    "False Positve: theme_exists_pred = 1 & theme_exists_val = 0\n",
    "\n",
    "True Negative: theme_exists_pred = null & theme_exists_val = 0\n",
    "\n",
    "False Negative: theme_exists_pred = null & theme_exists_val = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confuse_mat_exists(df_pred, df_val, label):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for pred, val in list(zip(df_pred[label], df_val[label])):\n",
    "        if pred == 1 and val == 1:\n",
    "            tp += 1\n",
    "        elif pd.isnull(pred) == True and val == 0:\n",
    "            tn += 1\n",
    "        elif pred == 1 and val == 0:\n",
    "            fp += 1\n",
    "        elif pd.isnull(pred) == True and val == 1:\n",
    "            fn += 1\n",
    "    return make_confuse_mat(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat2 = confuse_mat_exists(model_df, human_df, 'use_theme_exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100, 55], [10, 133]]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_mat_exists(model_df, human_df, 'use_theme_exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_score(mat):\n",
    "    #takes in argument as a 2x2 confonsion matrix per Task3 request\n",
    "    #[[true positve, false positive], [false negative, true negative]]\n",
    "    #accurancy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    return (mat[0][0] + mat[1][1]) / (mat[0][0] + mat[1][1] + mat[0][1] + mat[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_score(mat):\n",
    "    #takes in argument as a 2x2 confonsion matrix per Task3 request\n",
    "    #[[true positve, false positive], [false negative, true negative]]\n",
    "    #precision = (TP) / (TP + FP)\n",
    "    #Answers what proportion of positive identifications were actually correct\n",
    "    \n",
    "    return (mat[0][0]) / (mat[0][0] + mat[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_score(mat):\n",
    "    #takes in argument as a 2x2 confonsion matrix per Task3 request\n",
    "    #[[true positve, false positive], [false negative, true negative]]\n",
    "    #recall = (TP) / (TP + FN)\n",
    "    #Answers what proportion of actual positives was identified correctly\n",
    "    \n",
    "    return (mat[0][0]) / (mat[0][0] + mat[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(precision, recall):\n",
    "    #takes in arguments precision and recall scores\n",
    "    #recall = 2 x ((precision x recall)/(precision + recall))\n",
    "    #harmonic mean of precision and recall\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(mat2)\n",
    "prec = precision_score(mat2)\n",
    "recall = recall_score(mat2)\n",
    "f1 = f1_score(prec, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.781879\n",
      "precision: 0.645161\n",
      "recall: 0.909091\n",
      "f1-score: 0.754717\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {acc:.6}')\n",
    "print(f'precision: {prec:.6}')\n",
    "print(f'recall: {recall:.6}')\n",
    "print(f'f1-score: {f1:.6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 298 entries, 0 to 297\n",
      "Data columns (total 16 columns):\n",
      "_id                        298 non-null object\n",
      "domain_global_string       298 non-null object\n",
      "review_rating              298 non-null int64\n",
      "notes                      97 non-null object\n",
      "review_text                298 non-null object\n",
      "review_title               278 non-null object\n",
      "use_sentiment_label        110 non-null object\n",
      "use_theme_exists           298 non-null int64\n",
      "fit_sentiment_label        209 non-null object\n",
      "fit_theme_exists           298 non-null int64\n",
      "value_sentiment_label      101 non-null object\n",
      "value_theme_exists         298 non-null int64\n",
      "style_sentiment_label      120 non-null object\n",
      "style_theme_exists         298 non-null int64\n",
      "quality_sentiment_label    189 non-null object\n",
      "quality_theme_exists       297 non-null float64\n",
      "dtypes: float64(1), int64(5), object(10)\n",
      "memory usage: 37.3+ KB\n"
     ]
    }
   ],
   "source": [
    "human_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for the All Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_themes(df_pred, df_val):\n",
    "    \"\"\"\n",
    "    Calulates the precision, recall, accuracy and f1 scores for\n",
    "    the predictions of a model against its validator.\n",
    "    \n",
    "    Prints out results to console.  Does not return any values.\n",
    "    \n",
    "    df_pred: Dataframe of the predication results\n",
    "    df_cal: Dataframe of the validation results\n",
    "    \"\"\"\n",
    "    \n",
    "    #Get confusion matrices for theme_exists\n",
    "    fit_exists_mat = confuse_mat_exists(df_pred, df_val, 'fit_theme_exists')\n",
    "    quality_exists_mat = confuse_mat_exists(df_pred, df_val, 'quality_theme_exists')\n",
    "    style_exists_mat = confuse_mat_exists(df_pred, df_val, 'style_theme_exists')\n",
    "    use_exists_mat = confuse_mat_exists(df_pred, df_val, 'use_theme_exists')\n",
    "    value_exists_mat = confuse_mat_exists(df_pred, df_val, 'value_theme_exists')\n",
    "    \n",
    "    #Store matrices in a list\n",
    "    exists_mats = [fit_exists_mat, quality_exists_mat, style_exists_mat, use_exists_mat, value_exists_mat]\n",
    "    \n",
    "    #Get confusion matrices for theme_sentiment_label\n",
    "    fit_sentiment_mat = confuse_mat_label(df_pred, df_val, 'fit_sentiment_label')\n",
    "    quality_sentiment_mat = confuse_mat_label(df_pred, df_val, 'quality_sentiment_label')\n",
    "    style_sentiment_mat = confuse_mat_label(df_pred, df_val, 'style_sentiment_label')\n",
    "    use_sentiment_mat = confuse_mat_label(df_pred, df_val, 'use_sentiment_label')\n",
    "    value_sentiment_mat = confuse_mat_label(df_pred, df_val, 'value_sentiment_label')\n",
    "    \n",
    "    #Store matrices in a list\n",
    "    sent_mats = [fit_sentiment_mat, quality_sentiment_mat, style_sentiment_mat, use_sentiment_mat, value_sentiment_mat]\n",
    "    \n",
    "    #list of theme labels\n",
    "    #padding soem whitespace to format print out better\n",
    "    theme_labels = ['fit    ', 'quality', 'style  ', 'use    ', 'value  ']\n",
    "    \n",
    "    #Print heading with padding\n",
    "    print(\"                  Theme_Exists Theme_Sentiment\")\n",
    "    \n",
    "    #Loop over matrices and theme labels to calculate and print accuracy scores\n",
    "    for exists_mat, sent_mat, lab in list(zip(exists_mats, sent_mats, theme_labels)):\n",
    "        exists_acc = accuracy_score(exists_mat)\n",
    "        sent_acc = accuracy_score(sent_mat)\n",
    "        print(f'Accuracy {lab} : {exists_acc:.6f}    {sent_acc:.6f}')\n",
    "    \n",
    "    #Loop over matrices and theme labels to calculate and print f1 scores\n",
    "    for exists_mat, sent_mat, lab in list(zip(exists_mats, sent_mats, theme_labels)):\n",
    "        exists_recall = recall_score(exists_mat)\n",
    "        sent_recall = recall_score(sent_mat)\n",
    "        exists_prec = precision_score(exists_mat)\n",
    "        sent_prec = precision_score(sent_mat)\n",
    "        exists_f1 = f1_score(exists_prec, exists_recall)\n",
    "        sent_f1 = f1_score(sent_prec, sent_recall)\n",
    "        print(f'F-Measure {lab}: {exists_f1:.6f}    {sent_f1:.6f}')\n",
    "    \n",
    "    #Loop over matrices and theme labels to calculate and print precision scores\n",
    "    for exists_mat, sent_mat, lab in list(zip(exists_mats, sent_mats, theme_labels)):\n",
    "        exists_prec = precision_score(exists_mat)\n",
    "        sent_prec = precision_score(sent_mat)\n",
    "        print(f'Precision {lab}: {exists_prec:.6f}    {sent_prec:.6f}')\n",
    "    \n",
    "    #Loop over matrices and theme labels to calculate and print recall scores\n",
    "    for exists_mat, sent_mat, lab in list(zip(exists_mats, sent_mats, theme_labels)):\n",
    "        exists_recall = recall_score(exists_mat)\n",
    "        sent_recall = recall_score(sent_mat)\n",
    "        print(f'Recall {lab}   : {exists_recall:.6f}    {sent_recall:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Theme_Exists Theme_Sentiment\n",
      "Accuracy fit     : 0.859060    0.905263\n",
      "Accuracy quality : 0.801347    0.803797\n",
      "Accuracy style   : 0.657718    0.938776\n",
      "Accuracy use     : 0.781879    0.937500\n",
      "Accuracy value   : 0.862416    0.930556\n",
      "F-Measure fit    : 0.901408    0.948571\n",
      "F-Measure quality: 0.851385    0.874494\n",
      "F-Measure style  : 0.662252    0.968085\n",
      "F-Measure use    : 0.754717    0.967033\n",
      "F-Measure value  : 0.787565    0.961240\n",
      "Precision fit    : 0.857143    0.917127\n",
      "Precision quality: 0.797170    0.805970\n",
      "Precision style  : 0.549451    0.989130\n",
      "Precision use    : 0.645161    0.967033\n",
      "Precision value  : 0.775510    0.939394\n",
      "Recall fit       : 0.950495    0.982249\n",
      "Recall quality   : 0.913514    0.955752\n",
      "Recall style     : 0.833333    0.947917\n",
      "Recall use       : 0.909091    0.967033\n",
      "Recall value     : 0.800000    0.984127\n"
     ]
    }
   ],
   "source": [
    "analyze_themes(model_df, human_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There also exists a Python script called metrics.py that be run in the command prompt by typing:\n",
    "\n",
    "python metrics.py APPAREL_ids_1_2019.csv APPAREL_ODOM_1_2019.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
